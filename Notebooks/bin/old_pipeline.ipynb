{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_arr = 0.3 # pearson correlation coefficient\n",
    "vif_arr = 5 # vif coefficient\n",
    "features_arr = 10 # total number of features to be selected from backward feature selection\n",
    "iv_upper_limit = 0.5 # upper threshold of iv\n",
    "iv_lower_limit = 0.02 # lower threshold of iv\n",
    "seed = 9\n",
    "class_weight_dict = 'balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shashankgupta/Documents/code/git_project/plaid_credit\n",
      "/Users/shashankgupta/Documents/code/git_project/plaid_credit/Data\n",
      "raw data file loaded with shape : (646, 243) \n"
     ]
    }
   ],
   "source": [
    "# Import Packages \n",
    "import sys\n",
    "import pandas as pd \n",
    "import os \n",
    "import json\n",
    "import pickle\n",
    "import plotly.express as px\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "# os.environ['PYTHONHASHSEED']=str(42)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed)\n",
    "\n",
    "import os \n",
    "cwd = os.getcwd()\n",
    "\n",
    "# move to previous direc\n",
    "os.chdir('../')\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "# move to data direc\n",
    "os.chdir('./data')\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "\n",
    "# Reading Raw Data \n",
    "df = pd.read_pickle(f'/Users/shashankgupta/Documents/code/git_project/plaid_credit/data/final_dataset.pkl')\n",
    "# df2 = pd.read_pickle('')\n",
    "print(f\"raw data file loaded with shape : {df.shape} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shashankgupta/Documents/code/git_project/plaid_credit\n",
      "/Users/shashankgupta/Documents/code/git_project/plaid_credit/Code/src\n",
      "params file loaded ..\n",
      "params file loaded ..\n",
      "{'seed': 42, 'test_size': 0.3, 'target': 'DPD_plus_15', 'corr_thresh': 0.3, 'vif_thresh': 7, 'model': LogisticRegression(), 'forward_move': True, 'num_features': 10, 'bins': 5, 'upper_iv': 0.5, 'lower_iv': 0.02, 'params_log_reg': {'penalty': 'l1', 'random_state': 42, 'solver': 'liblinear', 'class_weight': {0: 0.1, 1: 0.9}}, 'pipeline_os': {'scale_type': StandardScaler(), 'target': 'DPD_plus_15'}}\n",
      "utils module loaded ..\n",
      "custom novo ds modules loaded ..\n",
      "all objects inititated ..\n",
      "\n",
      "Basic Flow : \n",
      "\n",
      "    Preprocess -> Transform -> Model Building -> Metrics \n",
      "\n",
      "\n",
      "/Users/shashankgupta/Documents/code/git_project/plaid_credit/Code/src/modules\n",
      "/Users/shashankgupta/Documents/code/git_project/plaid_credit/Code/src/modules\n",
      "custom novo ds modules loaded ..\n",
      "all objects inititated ..\n",
      "\n",
      "Basic Flow : \n",
      "\n",
      "    Preprocess -> Transform -> Model Building -> Metrics \n",
      "\n",
      "\n",
      "custom novo ds modules loaded ..\n",
      "/Users/shashankgupta/Documents/code/git_project/plaid_credit/Code/src\n",
      "/Users/shashankgupta/Documents/code/git_project/plaid_credit/Code\n",
      "/Users/shashankgupta/Documents/code/git_project/plaid_credit/Code/params\n",
      "params file loaded ..\n",
      "{'seed': 9, 'test_size': 0.3, 'target': 'target', 'corr_thresh': 0.4, 'vif_thresh': 5, 'model': LogisticRegression(), 'forward_move': True, 'num_features': 10, 'bins': 5, 'upper_iv': 0.5, 'lower_iv': 0.02, 'params_log_reg': {'penalty': 'l1', 'random_state': 9, 'solver': 'liblinear', 'class_weight': 'balanced'}, 'pipeline_os': {'scale_type': StandardScaler(), 'target': 'target'}}\n"
     ]
    }
   ],
   "source": [
    "# Import Sklearn Modules \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, Normalizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# move to previous direc\n",
    "os.chdir('../')\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "# move to code/src direc\n",
    "os.chdir('./code/src')\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "from utils import Utils\n",
    "from pipeline_blocks import PipelineBlocks\n",
    "from pipeline import PipelineTypes, PipelineTest\n",
    "\n",
    "# move to modules direc\n",
    "os.chdir('./modules')\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "os.chdir('/Users/shashankgupta/Documents/code/git_project/plaid_credit/code/src/modules')\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "# Import Other Modules\n",
    "from preprocess import Convert, MissingValues, Outlier, FeatureSelection\n",
    "from transform import Scaler, Transform, Selection\n",
    "from modeling import ModelBuild, ModelMetric\n",
    "from gridsearch import Grid\n",
    "print(f\"custom novo ds modules loaded ..\")\n",
    "\n",
    "\n",
    "# Opening Params Json File\n",
    "\n",
    "# move to previous direc\n",
    "os.chdir('../')\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "# move to previous direc\n",
    "os.chdir('../')\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "# move to params folder\n",
    "os.chdir('./params')\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "f = open('params.txt')\n",
    "params_data = json.load(f)\n",
    "print(f\"params file loaded ..\")\n",
    "params_data['model'] = LogisticRegression()\n",
    "\n",
    "params_data['forward_move'] = True\n",
    "params_data['params_log_reg']['class_weight'] = class_weight_dict\n",
    "params_data['pipeline_os']['scale_type']= StandardScaler()\n",
    "params_data['seed'] = seed\n",
    "print(f\"{params_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all objects inititated ..\n"
     ]
    }
   ],
   "source": [
    "# Object Initiation \n",
    "sc_min_max = Scaler(MinMaxScaler())\n",
    "sc_std_scaler = Scaler(StandardScaler())\n",
    "sc_robust_scaler = Scaler(RobustScaler())\n",
    "sc_norm = Scaler(Normalizer())\n",
    "\n",
    "cv = Convert()\n",
    "mv = MissingValues()\n",
    "ot = Outlier()\n",
    "ut = Utils()\n",
    "\n",
    "tf = Transform()\n",
    "sel = Selection()\n",
    "ft = FeatureSelection()\n",
    "\n",
    "mb = ModelBuild()\n",
    "mm = ModelMetric()\n",
    "\n",
    "pb = PipelineBlocks()\n",
    "pt = PipelineTypes()\n",
    "ptest = PipelineTest()\n",
    "\n",
    "gr = Grid()\n",
    "\n",
    "\n",
    "print(f\"all objects inititated ..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>lending_business_id</th>\n",
       "      <th>decision_date</th>\n",
       "      <th>drawn_flag</th>\n",
       "      <th>everDPD_15</th>\n",
       "      <th>fico_score</th>\n",
       "      <th>target</th>\n",
       "      <th>loans_flag</th>\n",
       "      <th>payroll_flag</th>\n",
       "      <th>pos_flag</th>\n",
       "      <th>...</th>\n",
       "      <th>sum_credits_grt_1500_6M</th>\n",
       "      <th>ratio_credits_lessthan_100_1M_3M</th>\n",
       "      <th>ratio_credits_lessthan_100_1M_6M</th>\n",
       "      <th>ratio_credits_grt_500_1M_3M</th>\n",
       "      <th>ratio_credits_grt_500_1M_6M</th>\n",
       "      <th>ratio_credits_grt_1500_1M_3M</th>\n",
       "      <th>ratio_credits_grt_1500_1M_6M</th>\n",
       "      <th>txn_each_mth_flag</th>\n",
       "      <th>txn_grt_100_each_mth_flag</th>\n",
       "      <th>txn_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a2317f88-325b-43ee-9423-6c711856555b</td>\n",
       "      <td>01e38425-5486-4c95-b6b0-de5c57319255</td>\n",
       "      <td>2023-02-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>721</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>71528.95</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>252c9a3f-338f-43fc-893f-87e4c8184e8c</td>\n",
       "      <td>166d62fb-70ed-4214-8a75-1223dfbbd06e</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>846</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42851.39</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>420bb9d6-c156-4e29-8060-420fa8753e7f</td>\n",
       "      <td>2c5dbbbc-327b-48ac-a737-73dc0c2a4d26</td>\n",
       "      <td>2023-03-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>720</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13647.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d9f1ffe7-f652-45ec-bdd6-5d530cf6a24a</td>\n",
       "      <td>588d7169-4d5c-4725-bc69-3e6d5e32d394</td>\n",
       "      <td>2023-02-15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>720</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>79422.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>588127e8-c54e-42d0-955a-a22e64207a2f</td>\n",
       "      <td>4bbe29b6-f631-4146-829c-880d71809e26</td>\n",
       "      <td>2023-03-24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>687</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1500.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            business_id                   lending_business_id  \\\n",
       "0  a2317f88-325b-43ee-9423-6c711856555b  01e38425-5486-4c95-b6b0-de5c57319255   \n",
       "1  252c9a3f-338f-43fc-893f-87e4c8184e8c  166d62fb-70ed-4214-8a75-1223dfbbd06e   \n",
       "2  420bb9d6-c156-4e29-8060-420fa8753e7f  2c5dbbbc-327b-48ac-a737-73dc0c2a4d26   \n",
       "3  d9f1ffe7-f652-45ec-bdd6-5d530cf6a24a  588d7169-4d5c-4725-bc69-3e6d5e32d394   \n",
       "4  588127e8-c54e-42d0-955a-a22e64207a2f  4bbe29b6-f631-4146-829c-880d71809e26   \n",
       "\n",
       "  decision_date drawn_flag everDPD_15 fico_score target  loans_flag  \\\n",
       "0    2023-02-02          1          0        721      0         0.0   \n",
       "1    2023-03-15          1          0        846      0         1.0   \n",
       "2    2023-03-07          1          0        720      0         0.0   \n",
       "3    2023-02-15          1          0        720      0         0.0   \n",
       "4    2023-03-24          1          0        687      0         0.0   \n",
       "\n",
       "   payroll_flag  pos_flag  ...  sum_credits_grt_1500_6M  \\\n",
       "0           1.0       1.0  ...                 71528.95   \n",
       "1           0.0       1.0  ...                 42851.39   \n",
       "2           0.0       0.0  ...                 13647.10   \n",
       "3           1.0       0.0  ...                 79422.72   \n",
       "4           0.0       0.0  ...                  1500.00   \n",
       "\n",
       "   ratio_credits_lessthan_100_1M_3M  ratio_credits_lessthan_100_1M_6M  \\\n",
       "0                          0.333333                              0.20   \n",
       "1                          0.272727                              0.15   \n",
       "2                               NaN                               NaN   \n",
       "3                               NaN                               NaN   \n",
       "4                               NaN                               NaN   \n",
       "\n",
       "   ratio_credits_grt_500_1M_3M  ratio_credits_grt_500_1M_6M  \\\n",
       "0                     0.363636                     0.200000   \n",
       "1                     0.473684                     0.243243   \n",
       "2                          NaN                          NaN   \n",
       "3                     0.181818                     0.105263   \n",
       "4                     0.333333                     0.166667   \n",
       "\n",
       "   ratio_credits_grt_1500_1M_3M  ratio_credits_grt_1500_1M_6M  \\\n",
       "0                          0.40                      0.235294   \n",
       "1                          0.25                      0.125000   \n",
       "2                           NaN                           NaN   \n",
       "3                          0.10                      0.058824   \n",
       "4                          0.50                      0.500000   \n",
       "\n",
       "   txn_each_mth_flag  txn_grt_100_each_mth_flag  txn_flag  \n",
       "0                1.0                        1.0       1.0  \n",
       "1                1.0                        1.0       1.0  \n",
       "2                0.0                        0.0       1.0  \n",
       "3                1.0                        1.0       1.0  \n",
       "4                0.0                        0.0       1.0  \n",
       "\n",
       "[5 rows x 243 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(637, 243)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['txn_flag']==1]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(637, 236)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['business_id', 'lending_business_id','decision_date','drawn_flag', 'everDPD_15', 'fico_score','txn_flag'], axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    505\n",
       "1    132\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>loans_flag</th>\n",
       "      <th>payroll_flag</th>\n",
       "      <th>pos_flag</th>\n",
       "      <th>ecom_flag</th>\n",
       "      <th>third_party_flag</th>\n",
       "      <th>service_flag</th>\n",
       "      <th>shops_flag</th>\n",
       "      <th>ach_flag</th>\n",
       "      <th>total_credit_count_1M</th>\n",
       "      <th>...</th>\n",
       "      <th>count_credits_grt_1500_6M</th>\n",
       "      <th>sum_credits_grt_1500_6M</th>\n",
       "      <th>ratio_credits_lessthan_100_1M_3M</th>\n",
       "      <th>ratio_credits_lessthan_100_1M_6M</th>\n",
       "      <th>ratio_credits_grt_500_1M_3M</th>\n",
       "      <th>ratio_credits_grt_500_1M_6M</th>\n",
       "      <th>ratio_credits_grt_1500_1M_3M</th>\n",
       "      <th>ratio_credits_grt_1500_1M_6M</th>\n",
       "      <th>txn_each_mth_flag</th>\n",
       "      <th>txn_grt_100_each_mth_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>71528.95</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>42851.39</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13647.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>79422.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1500.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  target  loans_flag  payroll_flag  pos_flag  ecom_flag  third_party_flag  \\\n",
       "0      0         0.0           1.0       1.0        1.0               1.0   \n",
       "1      0         1.0           0.0       1.0        0.0               1.0   \n",
       "2      0         0.0           0.0       0.0        0.0               0.0   \n",
       "3      0         0.0           1.0       0.0        1.0               1.0   \n",
       "4      0         0.0           0.0       0.0        0.0               0.0   \n",
       "\n",
       "   service_flag  shops_flag  ach_flag  total_credit_count_1M  ...  \\\n",
       "0           0.0         0.0       0.0                   11.0  ...   \n",
       "1           0.0         0.0       0.0                   12.0  ...   \n",
       "2           0.0         0.0       0.0                    NaN  ...   \n",
       "3           1.0         1.0       0.0                    3.0  ...   \n",
       "4           1.0         0.0       0.0                    1.0  ...   \n",
       "\n",
       "   count_credits_grt_1500_6M  sum_credits_grt_1500_6M  \\\n",
       "0                       16.0                 71528.95   \n",
       "1                       15.0                 42851.39   \n",
       "2                        1.0                 13647.10   \n",
       "3                       16.0                 79422.72   \n",
       "4                        1.0                  1500.00   \n",
       "\n",
       "   ratio_credits_lessthan_100_1M_3M  ratio_credits_lessthan_100_1M_6M  \\\n",
       "0                          0.333333                              0.20   \n",
       "1                          0.272727                              0.15   \n",
       "2                               NaN                               NaN   \n",
       "3                               NaN                               NaN   \n",
       "4                               NaN                               NaN   \n",
       "\n",
       "   ratio_credits_grt_500_1M_3M  ratio_credits_grt_500_1M_6M  \\\n",
       "0                     0.363636                     0.200000   \n",
       "1                     0.473684                     0.243243   \n",
       "2                          NaN                          NaN   \n",
       "3                     0.181818                     0.105263   \n",
       "4                     0.333333                     0.166667   \n",
       "\n",
       "   ratio_credits_grt_1500_1M_3M  ratio_credits_grt_1500_1M_6M  \\\n",
       "0                          0.40                      0.235294   \n",
       "1                          0.25                      0.125000   \n",
       "2                           NaN                           NaN   \n",
       "3                          0.10                      0.058824   \n",
       "4                          0.50                      0.500000   \n",
       "\n",
       "   txn_each_mth_flag  txn_grt_100_each_mth_flag  \n",
       "0                1.0                        1.0  \n",
       "1                1.0                        1.0  \n",
       "2                0.0                        0.0  \n",
       "3                1.0                        1.0  \n",
       "4                0.0                        0.0  \n",
       "\n",
       "[5 rows x 236 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = df.copy()\n",
    "df2 = df.copy()\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>loans_flag</th>\n",
       "      <th>payroll_flag</th>\n",
       "      <th>pos_flag</th>\n",
       "      <th>ecom_flag</th>\n",
       "      <th>third_party_flag</th>\n",
       "      <th>service_flag</th>\n",
       "      <th>shops_flag</th>\n",
       "      <th>ach_flag</th>\n",
       "      <th>total_credit_count_1M</th>\n",
       "      <th>...</th>\n",
       "      <th>count_credits_grt_1500_6M</th>\n",
       "      <th>sum_credits_grt_1500_6M</th>\n",
       "      <th>ratio_credits_lessthan_100_1M_3M</th>\n",
       "      <th>ratio_credits_lessthan_100_1M_6M</th>\n",
       "      <th>ratio_credits_grt_500_1M_3M</th>\n",
       "      <th>ratio_credits_grt_500_1M_6M</th>\n",
       "      <th>ratio_credits_grt_1500_1M_3M</th>\n",
       "      <th>ratio_credits_grt_1500_1M_6M</th>\n",
       "      <th>txn_each_mth_flag</th>\n",
       "      <th>txn_grt_100_each_mth_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>71528.95</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>42851.39</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13647.10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>79422.72</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1500.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  target  loans_flag  payroll_flag  pos_flag  ecom_flag  third_party_flag  \\\n",
       "0      0         0.0           1.0       1.0        1.0               1.0   \n",
       "1      0         1.0           0.0       1.0        0.0               1.0   \n",
       "2      0         0.0           0.0       0.0        0.0               0.0   \n",
       "3      0         0.0           1.0       0.0        1.0               1.0   \n",
       "4      0         0.0           0.0       0.0        0.0               0.0   \n",
       "\n",
       "   service_flag  shops_flag  ach_flag  total_credit_count_1M  ...  \\\n",
       "0           0.0         0.0       0.0                   11.0  ...   \n",
       "1           0.0         0.0       0.0                   12.0  ...   \n",
       "2           0.0         0.0       0.0                    0.0  ...   \n",
       "3           1.0         1.0       0.0                    3.0  ...   \n",
       "4           1.0         0.0       0.0                    1.0  ...   \n",
       "\n",
       "   count_credits_grt_1500_6M  sum_credits_grt_1500_6M  \\\n",
       "0                       16.0                 71528.95   \n",
       "1                       15.0                 42851.39   \n",
       "2                        1.0                 13647.10   \n",
       "3                       16.0                 79422.72   \n",
       "4                        1.0                  1500.00   \n",
       "\n",
       "   ratio_credits_lessthan_100_1M_3M  ratio_credits_lessthan_100_1M_6M  \\\n",
       "0                          0.333333                              0.20   \n",
       "1                          0.272727                              0.15   \n",
       "2                          0.000000                              0.00   \n",
       "3                          0.000000                              0.00   \n",
       "4                          0.000000                              0.00   \n",
       "\n",
       "   ratio_credits_grt_500_1M_3M  ratio_credits_grt_500_1M_6M  \\\n",
       "0                     0.363636                     0.200000   \n",
       "1                     0.473684                     0.243243   \n",
       "2                     0.000000                     0.000000   \n",
       "3                     0.181818                     0.105263   \n",
       "4                     0.333333                     0.166667   \n",
       "\n",
       "   ratio_credits_grt_1500_1M_3M  ratio_credits_grt_1500_1M_6M  \\\n",
       "0                          0.40                      0.235294   \n",
       "1                          0.25                      0.125000   \n",
       "2                          0.00                      0.000000   \n",
       "3                          0.10                      0.058824   \n",
       "4                          0.50                      0.500000   \n",
       "\n",
       "   txn_each_mth_flag  txn_grt_100_each_mth_flag  \n",
       "0                1.0                        1.0  \n",
       "1                1.0                        1.0  \n",
       "2                0.0                        0.0  \n",
       "3                1.0                        1.0  \n",
       "4                0.0                        0.0  \n",
       "\n",
       "[5 rows x 236 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = df_raw.fillna(0)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (445, 235) | y_train.shape = (445,) | x_test.shape = (192, 235) | y_test.shape = (192,)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = mb.split_test_train(df_raw, target_column='target', test_size=0.3, random_state = seed)\n",
    "print(f'{x_train.shape = }', '|' ,f'{y_train.shape = }', '|' ,f'{x_test.shape = }', '|' ,f'{y_test.shape = }')\n",
    "\n",
    "\n",
    "# copy to df\n",
    "df = x_train.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'float64': 235}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get datatypes frequency\n",
    "def get_datatypes_freq(df):\n",
    "    type_dct = {str(k): list(v) for k, v in df.groupby(df.dtypes, axis=1)}\n",
    "    type_dct_info = {k: len(v) for k, v in type_dct.items()}\n",
    "    return type_dct, type_dct_info\n",
    "\n",
    "type_dct, type_dct_info = get_datatypes_freq(df)\n",
    "type_dct_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treat missing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_df = pd.DataFrame(df.isnull().sum().sort_values(ascending=False),columns = ['null_count'])\n",
    "null_df = null_df[null_df['null_count']>0]\n",
    "null_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columns except for booleans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get boolean columns\n",
    "def findbool(df):\n",
    "    bool_arr = []\n",
    "    for col in df.columns: \n",
    "        if (len(df[col].unique())<=2):\n",
    "            bool_arr.append(col)\n",
    "    return(bool_arr)\n",
    "\n",
    "bool_col_list = findbool(df)\n",
    "len(bool_col_list)\n",
    "\n",
    "type_dct, type_dct_info = get_datatypes_freq(df)\n",
    "col_list = ( type_dct['float64'])\n",
    "col_list_excpt_bool = [column for column in col_list if column not in bool_col_list]\n",
    "len(col_list_excpt_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store train data params for substitution in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params = pd.DataFrame(columns=['feature', 'median', 'lower_limit', 'upper_limit'])\n",
    "data_params['feature'] = col_list_excpt_bool\n",
    "data_params['median'] = df[col_list_excpt_bool].median().values\n",
    "data_params['lower_limit'] = df[col_list_excpt_bool].quantile([0.01, 0.99]).values[0]\n",
    "data_params['upper_limit'] = df[col_list_excpt_bool].quantile([0.01, 0.99]).values[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Min Max Capping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.DataFrame(columns=['feature', 'lower_cap', 'upper_cap', 'lower_values_capped', 'upper_values_capped'])\n",
    "df_info['feature'] = col_list_excpt_bool\n",
    "for col in col_list_excpt_bool:\n",
    "    percentiles = df[col].quantile([0.01, 0.99]).values\n",
    "    df_info.loc[df_info['feature'] == col, 'lower_cap'] = percentiles[0]\n",
    "    df_info.loc[df_info['feature'] == col, 'upper_cap'] = percentiles[1]\n",
    "    df_info.loc[df_info['feature'] == col, 'lower_values_capped'] = df[col][df[col] < percentiles[0]].shape[0]/df.shape[0]\n",
    "    df_info.loc[df_info['feature'] == col, 'upper_values_capped'] = df[col][df[col] > percentiles[1]].shape[0]/df.shape[0]\n",
    "    df[col][df[col] < percentiles[0]] = percentiles[0]\n",
    "    df[col][df[col] > percentiles[1]] = percentiles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info.sort_values(by='lower_values_capped', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(445, 235)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df_trans = df.copy()\n",
    "# scaling\n",
    "transformer = StandardScaler().fit(df[col_list_excpt_bool])\n",
    "\n",
    "df[col_list_excpt_bool] = pd.DataFrame(transformer.transform(df[col_list_excpt_bool]), columns=col_list_excpt_bool)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(col_list_excpt_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IV & WOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## iv_woe\n",
    "\n",
    "## iv_woe\n",
    "\n",
    "def iv_woe(data, target, bins=10, show_woe=False):\n",
    "    \n",
    "    #Empty Dataframe\n",
    "    newDF,woeDF = pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    #Extract Column Names\n",
    "    cols = data.columns\n",
    "    \n",
    "    #Run WOE and IV on all the independent variables\n",
    "    for ivars in cols[~cols.isin([target])]:\n",
    "        if (data[ivars].dtype.kind in 'bifc') and (len(np.unique(data[ivars]))>10):\n",
    "            binned_x = pd.qcut(data[ivars], bins,  duplicates='drop')\n",
    "            d0 = pd.DataFrame({'x': binned_x, 'y': data[target]})\n",
    "        else:\n",
    "            d0 = pd.DataFrame({'x': data[ivars], 'y': data[target]})\n",
    "\n",
    "        \n",
    "        # Calculate the number of events in each group (bin)\n",
    "        d = d0.groupby(\"x\", as_index=False).agg({\"y\": [\"count\", \"sum\"]})\n",
    "        d.columns = ['Cutoff', 'N', 'Events']\n",
    "        \n",
    "        # Calculate % of events in each group.\n",
    "        d['% of Events'] = np.maximum(d['Events'], 0.5) / d['Events'].sum()\n",
    "\n",
    "        # Calculate the non events in each group.\n",
    "        d['Non-Events'] = d['N'] - d['Events']\n",
    "        # Calculate % of non events in each group.\n",
    "        d['% of Non-Events'] = np.maximum(d['Non-Events'], 0.5) / d['Non-Events'].sum()\n",
    "\n",
    "        # Calculate WOE by taking natural log of division of % of non-events and % of events\n",
    "        d['WoE'] = np.log(d['% of Events']/d['% of Non-Events'])\n",
    "        d['IV'] = d['WoE'] * (d['% of Events'] - d['% of Non-Events'])\n",
    "        d.insert(loc=0, column='Variable', value=ivars)\n",
    "        print(\"Information value of \" + ivars + \" is \" + str(round(d['IV'].sum(),6)))\n",
    "        temp =pd.DataFrame({\"Variable\" : [ivars], \"IV\" : [d['IV'].sum()]}, columns = [\"Variable\", \"IV\"])\n",
    "        newDF=pd.concat([newDF,temp], axis=0)\n",
    "        woeDF=pd.concat([woeDF,d], axis=0)\n",
    "\n",
    "        #Show WOE Table\n",
    "        if show_woe == True:\n",
    "            print(d)\n",
    "    return newDF, woeDF\n",
    "\n",
    "# remove features on basis of IV\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "df['target'] = y_train\n",
    "temp = df.copy()\n",
    "t1, t2 = iv_woe(temp[np.append(col_list_excpt_bool,['target'])], 'target', bins=5, show_woe=False)\n",
    "feature_list = list(t1[ (t1['IV']<iv_upper_limit) & (t1['IV']>iv_lower_limit) ]['Variable'].values)\n",
    "len(feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation & VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view correlation\n",
    "corr_df, subset_df = sel.get_correlated_features(df, feature_list, thresh=corr_arr)\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove correlated features\n",
    "feature_list = sel.corr_iter(df, np.array(feature_list), thresh=corr_arr)\n",
    "feature_list = list(feature_list)\n",
    "len(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature list after iterative VIF elimination\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def vif_iter(df, iv, threshold=10):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = iv\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(df[iv].values, i) for i in range(len(iv))]\n",
    "    if len(vif_data[vif_data['VIF'] == np.inf]) > 0:\n",
    "        feature = vif_data[vif_data['VIF'] == np.inf]['feature'].iloc[0]\n",
    "        iv.remove(feature)\n",
    "        vif_iter(df, iv, threshold)\n",
    "    elif len(vif_data[vif_data['VIF'] > threshold]) > 0:\n",
    "        feature = vif_data.sort_values(by='VIF', ascending=False)['feature'].iloc[0]\n",
    "        iv.remove(feature)\n",
    "        vif_iter(df, iv, threshold)\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = iv\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(df[iv].values, i) for i in range(len(iv))]\n",
    "    return iv, vif_data\n",
    "\n",
    "feature_list, vif_df = vif_iter(df, feature_list, threshold=vif_arr)\n",
    "len(feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(penalty='l2', solver='liblinear', class_weight = class_weight_dict, random_state = seed)\n",
    "feat_list = ft.move_feature_selection(df[feature_list], y_train, num_features=features_arr,model=logit,forward = True)\n",
    "feat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_list = ['card_withdrawal_size_2m',\n",
    "#  'distinct_debit_txns_2m',\n",
    "#  'ratio_debit_credit_2m',\n",
    "#  'ratio_ach_debit_total_debit_2m',\n",
    "#  'ratio_ach_credit_total_credit_2m',\n",
    "#  'ratio_pd_freq_total_credit_1m',\n",
    "#  'avg_running_balance_2nd_m',\n",
    "#  'distinct_cashins_2m_prev',\n",
    "#  'ratio_amt_drawn_mom']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "params_log_reg = {'penalty': 'l2',\n",
    "                  'random_state': seed,\n",
    "                  'solver': 'liblinear',\n",
    "                  'class_weight': class_weight_dict}\n",
    "\n",
    "# model fit\n",
    "logreg_model = mb.classification_models(df[feat_list], y_train, params_log_reg, models=['log_reg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train cv scores\n",
    "cv_scores = mm.cross_validation(logreg_model, df[feat_list], y_train, scoring='roc_auc', folds=5, seed=seed)\n",
    "print('CV Scores -',np.round(cv_scores, 2))\n",
    "print('Mean of CV Scores -',np.round(np.mean(cv_scores),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train score\n",
    "mm.model_metrics(logreg_model.predict(df[feat_list]), np.array(y_train), logreg_model.predict_proba(df[feat_list]),tag=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = mm.feature_importance(logreg_model, df[feat_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = list(feat_imp.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp['abs_imp'] = abs(feat_imp['importance'])\n",
    "feat_imp.sort_values(by='abs_imp', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "x_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# treat missing values\n",
    "for col in x_test.columns[x_test.isnull().any(axis=0)]:\n",
    "    x_test[col].fillna(data_params[data_params['feature'] == col]['median'].values[0], inplace=True)\n",
    "\n",
    "# min max capping\n",
    "for col in col_list_excpt_bool:\n",
    "    lower_cap = data_params[data_params['feature'] == col]['lower_limit'].values[0]\n",
    "    upper_cap = data_params[data_params['feature'] == col]['upper_limit'].values[0]\n",
    "    x_test[col][x_test[col] < lower_cap] = lower_cap\n",
    "    x_test[col][x_test[col] > upper_cap] = upper_cap\n",
    "\n",
    "# scaling\n",
    "x_test[col_list_excpt_bool] = pd.DataFrame(transformer.transform(x_test[col_list_excpt_bool]), columns=col_list_excpt_bool)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test cv scores\n",
    "cv_scores = mm.cross_validation(logreg_model, x_test[feat_list], y_test, scoring='roc_auc', folds=5, seed=seed)\n",
    "print('CV Scores -',np.round(cv_scores, 2))\n",
    "print('Mean of CV Scores -',np.round(np.mean(cv_scores),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test score\n",
    "mm.model_metrics(logreg_model.predict(x_test[feat_list]), np.array(y_test), logreg_model.predict_proba(x_test[feat_list]),tag = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy df\n",
    "df_all = df_raw.copy()\n",
    "\n",
    "# reset index\n",
    "df_all.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# treat missing values\n",
    "for col in df_all.columns[df_all.isnull().any(axis=0)]:\n",
    "    df_all[col].fillna(data_params[data_params['feature'] == col]['median'].values[0], inplace=True)\n",
    "\n",
    "# min max capping\n",
    "for col in col_list_excpt_bool:\n",
    "    lower_cap = data_params[data_params['feature'] == col]['lower_limit'].values[0]\n",
    "    upper_cap = data_params[data_params['feature'] == col]['upper_limit'].values[0]\n",
    "    df_all[col][df_all[col] < lower_cap] = lower_cap\n",
    "    df_all[col][df_all[col] > upper_cap] = upper_cap\n",
    "\n",
    "# scaling\n",
    "df_all[col_list_excpt_bool] = pd.DataFrame(transformer.transform(df_all[col_list_excpt_bool]), columns=col_list_excpt_bool)\n",
    "df_all.shape\n",
    "\n",
    "predicted_probas = logreg_model.predict_proba(df_all[feat_list])\n",
    "df_all['proba'] = predicted_probas[:,1:].flatten()\n",
    "px.histogram(df_all['proba'], nbins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = mm.cross_validation(logreg_model, df_raw[feat_list], df_raw['DPD_plus_15'], scoring='roc_auc', folds=5, seed=seed)\n",
    "print('CV Scores -',np.round(cv_scores, 2))\n",
    "print('Mean of CV Scores -',np.round(np.mean(cv_scores),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rank Ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete dataset\n",
    "df_all['proba'] = np.round(df_all['proba'], 3)\n",
    "df_all['DecileRank']= pd.qcut(df_all['proba'], q = 4)\n",
    "df_stats = pd.DataFrame(df_all.groupby(by='DecileRank')['DPD_plus_15'].mean())\n",
    "df_stats['volume'] = df_all.groupby(by='DecileRank')['DPD_plus_15'].count()\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "x_train = df.copy()\n",
    "x_train.reset_index(drop=True,inplace=True)\n",
    "y_train.reset_index(drop=True,inplace=True)\n",
    "\n",
    "df_train = x_train.copy()\n",
    "df_train['DPD_plus_15'] = y_train\n",
    "df_train['proba'] = logreg_model.predict_proba(x_train[feat_list])[:,1:].flatten()\n",
    "\n",
    "df_train['proba'] = np.round(df_train['proba'], 3)\n",
    "df_train['DecileRank']= pd.qcut(df_train['proba'], q = 4)\n",
    "df_stats = pd.DataFrame(df_train.groupby(by='DecileRank')['DPD_plus_15'].mean())\n",
    "df_stats['volume'] = df_train.groupby(by='DecileRank')['DPD_plus_15'].count()\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "x_test.reset_index(drop=True,inplace=True)\n",
    "y_test.reset_index(drop=True,inplace=True)\n",
    "\n",
    "df_test = x_test.copy()\n",
    "df_test['DPD_plus_15'] = y_test\n",
    "df_test['proba'] = logreg_model.predict_proba(x_test[feat_list])[:,1:].flatten()\n",
    "\n",
    "df_test['proba'] = np.round(df_test['proba'], 3)\n",
    "df_test['DecileRank']= pd.qcut(df_test['proba'], q = 4)\n",
    "df_stats = pd.DataFrame(df_test.groupby(by='DecileRank')['DPD_plus_15'].mean())\n",
    "df_stats['volume'] = df_test.groupby(by='DecileRank')['DPD_plus_15'].count()\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving scale transaformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling for selected features\n",
    "transformer_object = StandardScaler().fit(df_trans[feature_list])\n",
    "\n",
    "df_trans[feature_list] = pd.DataFrame(transformer_object.transform(df[feature_list]), columns=feature_list)\n",
    "df_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save transaformer\n",
    "# file_name = 'scale_train_object.pkl'\n",
    "# path = '/Users/shashankgupta/Documents/code/git_project/redec/re_decisioning/Models/'\n",
    "# pickle.dump(transformer_object, open(path + file_name, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['DPD_plus_15'].sum()/len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_bucket(x):\n",
    "    if x > 0.56:\n",
    "        return 4\n",
    "    if x > 0.431:\n",
    "        return 3\n",
    "    if x > 0.255:\n",
    "        return 2\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_bucket(x):\n",
    "    if x > 0.8:\n",
    "        return '>0.8'\n",
    "    if x > 0.6:\n",
    "        return '0.6-0.8'\n",
    "    if x > 0.5:\n",
    "        return '0.5-0.6'\n",
    "    return '<0.5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['prob_bucket'] = df_all['proba'].apply(lambda x: prob_bucket(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['proba_bucket'] = df_all['proba'].apply(lambda x: target_bucket(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.groupby(['proba_bucket','emi_no'],as_index=False)['DPD_plus_15'].agg(['sum','count']).sort_values(['proba_bucket','emi_no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.groupby(['proba_bucket','DPD_plus_3'],as_index=False)['DPD_plus_15'].agg(['sum','count']).sort_values(['proba_bucket','DPD_plus_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.groupby('emi_no')['DPD_plus_15'].agg(['sum','count']).sort_values('emi_no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.groupby(['pilot_flag','pilot_period_flag','emi_no'])['DPD_plus_15'].agg(['sum','count']).sort_values(['pilot_flag','pilot_period_flag','emi_no'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prob bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.groupby(['prob_bucket'],as_index=False)['DPD_plus_15'].agg(['sum','count']).sort_values(['prob_bucket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test.shape)\n",
    "print(df_test[df_test['proba']>0.6].shape)\n",
    "print(df_test[df_test['proba']>0.7].shape)\n",
    "print(df_test[df_test['proba']>0.8].shape)\n",
    "print(df_test[df_test['proba']>0.9].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.groupby(['emi_no'],as_index=False)['DPD_plus_15'].agg(['sum','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Delinquency rate for (Prob > {}) - {} & proportion = {}%'.format(0.6,np.round(df_test.loc[df_test['proba']>0.6,'DPD_plus_15'].sum()/len(df_test[df_test['proba']>0.6]),2), np.round(len(df_test[df_test['proba']>0.6])*100/len(df_test),2)))\n",
    "print('Delinquency rate for (Prob > {}) - {} & proportion = {}%'.format(0.7,np.round(df_test.loc[df_test['proba']>0.7,'DPD_plus_15'].sum()/len(df_test[df_test['proba']>0.7]),2), np.round(len(df_test[df_test['proba']>0.7])*100/len(df_test),2)))\n",
    "print('Delinquency rate for (Prob > {}) - {} & proportion = {}%'.format(0.8,np.round(df_test.loc[df_test['proba']>0.8,'DPD_plus_15'].sum()/len(df_test[df_test['proba']>0.8]),2), np.round(len(df_test[df_test['proba']>0.8])*100/len(df_test),2)))\n",
    "print('Delinquency rate for (Prob > {}) - {} & proportion = {}%'.format(0.9,np.round(df_test.loc[df_test['proba']>0.9,'DPD_plus_15'].sum()/len(df_test[df_test['proba']>0.9]),2), np.round(len(df_test[df_test['proba']>0.9])*100/len(df_test),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['amount_debited_2m'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save data parameters\n",
    "# data_params = data_params[data_params['feature'].isin(feat_list)]\n",
    "# file_name = 'data_params_v2.pkl'\n",
    "# path = '/Users/shashankgupta/Documents/code/git_project/redec/re_decisioning/Models/'\n",
    "# data_params.to_pickle(path + file_name)\n",
    "\n",
    "\n",
    "# # save logit model\n",
    "# file_name = 'redec_3.pkl'\n",
    "# path = '/Users/shashankgupta/Documents/code/git_project/redec/re_decisioning/Models/'\n",
    "# pickle.dump(logreg_model, open(path + file_name,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.groupby('rs2_bin')['DPD_plus_15'].agg(['sum','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.groupby('rs2_bin')['proba'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buckets(x):\n",
    "    if x > 0.58:\n",
    "        return 1\n",
    "    if x > 0.46:\n",
    "        return 2\n",
    "    if x > 0.35:\n",
    "        return 3\n",
    "    if x > 0.20:\n",
    "        return 4\n",
    "    return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def buckets(x):\n",
    "#     if x > 0.587:\n",
    "#         return 1\n",
    "#     if x > 0.488:\n",
    "#         return 2\n",
    "#     if x > 0.383:\n",
    "#         return 3\n",
    "#     if x > 0.266:\n",
    "#         return 4\n",
    "#     return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['redec_bucket'] = df_all['proba'].apply(lambda x: buckets(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.groupby('redec_bucket')['DPD_plus_15'].agg(['sum','count']).to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['redec_score'] = (1 - df_all['proba'])*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.17 64-bit ('venv_plaid_credit')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9bbc33ec67b6e69663d9524a7cba3ebe2e2de2798633e20e7d227e00dd346ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
